# 마르코프 체인 (Markov Chain)

이 문서는 `markov_chain.py` 파일에 구현된 **마르코프 체인(Markov Chain)** 시뮬레이션 알고리즘에 대해 설명합니다.

## 개요

마르코프 체인은 특정 상태(State)에서 다른 상태로 변할 확률이 오직 현재 상태에만 의존하는 확률적 과정을 말합니다. 이 코드는 그래프 자료구조를 사용하여 상태 간의 전이 확률을 정의하고, 시뮬레이션을 통해 각 상태가 얼마나 자주 방문되는지 계산합니다.

## 주요 클래스: `MarkovChainGraphUndirectedUnweighted`

이 클래스는 마르코프 체인의 상태와 전이 확률을 관리합니다. (클래스 이름에 'UndirectedUnweighted'가 포함되어 있지만, 실제 동작은 유향 가중치 그래프와 유사하게 확률에 따라 방향성 있게 이동합니다.)

### 주요 메서드

- **`add_transition_probability(node1, node2, probability)`**:
  - `node1`에서 `node2`로 이동할 확률을 추가합니다.
  - 만약 노드가 그래프에 없다면 새로 생성합니다.
  - `self.connections[node1][node2] = probability` 형태로 저장됩니다.

- **`transition(node)`**:
  - 현재 상태(`node`)에서 다음 상태를 결정하여 반환합니다.
  - 0과 1 사이의 무작위 값(`random()`)을 생성합니다.
  - 현재 노드에서 갈 수 있는 모든 이웃 노드들의 확률을 누적하며 무작위 값과 비교하여 다음 노드를 선택합니다.

## 주요 함수: `get_transitions`

### `get_transitions(start, transitions, steps)`

- **목적**: 주어진 시작 상태와 전이 규칙을 바탕으로 마르코프 체인 시뮬레이션을 수행합니다.
- **매개변수**:
  - `start`: 시뮬레이션을 시작할 초기 상태(노드 이름).
  - `transitions`: `(출발 노드, 도착 노드, 확률)` 튜플들의 리스트.
  - `steps`: 시뮬레이션을 수행할 총 단계 수.
- **반환값**: 각 상태(노드)가 방문된 횟수를 담은 `Counter` 객체 (딕셔너리 형태).
- **동작 원리**:
  1. 그래프 객체를 생성하고 `transitions` 정보를 입력합니다.
  2. `start` 노드부터 시작하여 `steps`만큼 반복합니다.
  3. 각 단계마다 `graph.transition()`을 호출하여 다음 노드로 이동하고, 방문 횟수를 기록합니다.

## 사용법

`if __name__ == "__main__":` 블록의 `doctest` 예제를 통해 동작을 확인할 수 있습니다.

```python
transitions = [
    ('a', 'a', 0.9), ('a', 'b', 0.075), ('a', 'c', 0.025),
    ('b', 'a', 0.15), ('b', 'b', 0.8), ('b', 'c', 0.05),
    ('c', 'a', 0.25), ('c', 'b', 0.25), ('c', 'c', 0.5)
]

# 'a'에서 시작하여 5000번 이동 시뮬레이션
result = get_transitions('a', transitions, 5000)

# 결과 예시: {'a': 3xxx, 'b': 1xxx, 'c': xxx}
# 확률적으로 'a' 상태에 머무를 확률이 가장 높게 설정되어 있으므로 a의 방문 횟수가 가장 많습니다.
```

## 주의 사항
- 각 노드에서 나가는 전이 확률의 합은 1.0이 되어야 정확한 시뮬레이션이 가능합니다.
- `transition` 메서드는 확률의 누적 합을 사용하므로, 확률의 합이 1보다 작으면 아무 곳으로도 이동하지 못하고 빈 문자열(`""`)을 반환할 수 있습니다.
