# 로지스틱 회귀 (Logistic Regression)

이 문서는 `logistic_regression.py` 파일에 구현된 **로지스틱 회귀(Logistic Regression)** 알고리즘에 대해 설명합니다.

## 개요

로지스틱 회귀는 데이터를 두 개의 클래스(0 또는 1)로 분류하는 데 사용되는 통계적 기법입니다. 이 코드는 외부 라이브러리 없이 `numpy`만을 사용하여 로지스틱 회귀를 처음부터 구현하고, 붓꽃(Iris) 데이터셋을 사용하여 이진 분류를 수행합니다.

## 주요 함수

### `sigmoid_function(z)`
- **목적**: 시그모이드(Sigmoid) 활성화 함수를 계산합니다.
- **수식**: $\sigma(z) = \frac{1}{1 + e^{-z}}$
- **역할**: 선형 결합된 값을 0과 1 사이의 확률 값으로 변환합니다.

### `cost_function(h, y)`
- **목적**: 현재 모델의 예측값(`h`)과 실제값(`y`) 사이의 오차(비용)를 계산합니다.
- **방식**: 로그 손실(Log Loss) 또는 이진 크로스 엔트로피(Binary Cross-Entropy)를 사용합니다.

### `logistic_reg(alpha, X, y, max_iterations=70000)`
- **목적**: 경사 하강법(Gradient Descent)을 사용하여 모델을 학습시킵니다.
- **매개변수**:
  - `alpha`: 학습률 (Learning Rate).
  - `X`: 입력 특징 행렬.
  - `y`: 타겟 벡터.
  - `max_iterations`: 최대 반복 횟수.
- **동작**:
  1. 가중치(`theta`)를 0으로 초기화합니다.
  2. 반복문 내에서 예측값(`h`)을 계산하고, 오차에 대한 기울기(`gradient`)를 구합니다.
  3. 가중치를 업데이트합니다: $\theta := \theta - \alpha \times \nabla J(\theta)$
  4. 100번마다 손실 값을 출력합니다.

## 실행 과정 (`main` 블록)

1. **데이터 로드**: `sklearn.datasets`에서 Iris 데이터를 불러옵니다.
2. **데이터 전처리**:
   - 시각화를 위해 처음 두 개의 특징만 사용합니다.
   - 타겟 레이블을 0과 1(0이 아닌 것)로 변환하여 이진 분류 문제로 만듭니다.
3. **모델 학습**: `logistic_reg` 함수를 호출하여 최적의 가중치(`theta`)를 찾습니다.
4. **결과 시각화**:
   - 학습된 모델의 결정 경계(Decision Boundary)를 등고선(Contour plot)으로 그립니다.
   - 실제 데이터 포인트들을 산점도(Scatter plot)로 표시하여 분류 결과를 시각적으로 확인합니다.

## 사용법

스크립트를 실행하면 학습 과정의 손실 값이 출력되고, 결과 그래프 창이 나타납니다.

```python
# 실행 시 그래프 창이 열리며 결정 경계를 확인할 수 있습니다.
```

## 요구 사항
- `numpy`: 행렬 연산.
- `matplotlib`: 데이터 및 결정 경계 시각화.
- `sklearn`: 예제 데이터셋 로드.
